{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "adedd859-5ab3-4336-8e23-c4c0f5c4903c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from datetime import datetime  # Import the datetime module\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "58fb8cb3-bc6b-4585-a159-ff408fa15979",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "token = dbutils.widgets.get('token')\n",
    "artist_id_index = dbutils.widgets.get('artist_id_index')\n",
    "artist_id_index = int(artist_id_index)\n",
    "headers = {\"Authorization\": token}\n",
    "display(headers) \n",
    "\n",
    "# Assuming you have a CSV file uploaded to Databricks File System (DBFS)\n",
    "csv_file_path = \"/mnt/spotifyetlprojectdl/raw/raw-artist-ids/ds_raw_artist_ids.csv\"\n",
    "\n",
    "# Read CSV file into a DataFrame\n",
    "df = spark.read.csv(csv_file_path, header=True)\n",
    "\n",
    "# Display the DataFrame to see its structure\n",
    "df.show()\n",
    "\n",
    "# Collect album IDs as a list\n",
    "artist_ids = df.select(\"ArtistID\").rdd.flatMap(lambda x: x).collect()\n",
    "\n",
    "# Print each album ID\n",
    "for artist_id in artist_ids:\n",
    "    print(artist_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6877262f-6337-4e79-b3dc-4d2832f8d358",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "start_index = artist_id_index\n",
    "current_index = start_index  # Initialize current_index\n",
    "\n",
    "# Specify the destination folder for Exception DBFS\n",
    "exception_destination_folder = \"/dbfs/mnt/ingestion-exception\"\n",
    "\n",
    "def raise_custom_exception(error_message, current_index, response_code, retry_after=None):\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "    exception_dict = {\n",
    "        \"error_message\": error_message,\n",
    "        \"current_index\": str(current_index),\n",
    "        \"response_code\": response_code,\n",
    "        \"retry_after\": retry_after,\n",
    "        \"timestamp\": timestamp\n",
    "    }\n",
    "    \n",
    "    save_exception(exception_dict)\n",
    "    \n",
    "    exception_json = json.dumps(exception_dict)\n",
    "    raise Exception(exception_json)\n",
    "\n",
    "def save_exception(exception_dict):\n",
    "    # Generate a timestamp for the unique filename\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "\n",
    "    # Create unique filenames for Blob Storage and DBFS\n",
    "    \n",
    "    dbfs_log_file  = f\"{exception_destination_folder}/album_error_logs.json\"\n",
    "    print(\"Saving to DBFS:\", dbfs_log_file)\n",
    "\n",
    "    # Save the exception log to DBFS using open() and json.dump()\n",
    "    with open(dbfs_log_file, 'w') as json_file:\n",
    "        json.dump(exception_dict, json_file, indent=2)\n",
    "        \n",
    "        \n",
    "# Iterate over album IDs\n",
    "for artist_id in artist_ids[start_index:]:\n",
    "    offset = 0\n",
    "    limit = 50\n",
    "    while True:\n",
    "        search_url = f\"https://api.spotify.com/v1/artists/{artist_id}/albums?include_groups=album%2Csingle&limit={limit}&offset={offset}\"\n",
    "        try:\n",
    "            result = requests.get(search_url, headers=headers)\n",
    "            response_code = result.status_code  # Capture the response code\n",
    "            print(response_code)\n",
    "            if response_code == 429:\n",
    "                retry_after = result.headers.get('Retry-After')\n",
    "                error_message = \"Rate limit exceeded.\"\n",
    "                raise_custom_exception(error_message, current_index, response_code, retry_after)\n",
    "                \n",
    "            elif response_code == 401:\n",
    "                raise_custom_exception(f\"Bad or expired token.\", current_index, response_code)\n",
    "                   \n",
    "            elif response_code == 200:\n",
    "                albums = json.loads(result.content)\n",
    "                timestamp = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "                #Save album tracks to a JSON file in /mnt/incomming-albums\n",
    "                filename = f\"/dbfs/mnt/incoming-albums/{artist_id}_{offset}_incomming_albums_{timestamp}.json\"\n",
    "                with open(filename, 'w') as json_file:\n",
    "                    json.dump(albums, json_file, indent=2)\n",
    "                \n",
    "                current_index += 1\n",
    "                offset += len(albums[\"items\"])\n",
    "                \n",
    "            if len(albums[\"items\"]) < limit:\n",
    "                break\n",
    "                \n",
    "                   \n",
    "        except Exception as e:\n",
    "           \n",
    "            raise\n",
    "\n",
    "        \n",
    "dbutils.notebook.exit(\"Success\")\n",
    "     \n",
    "        \n",
    "        \n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Ingest Albums Notebook",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
